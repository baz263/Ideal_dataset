{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a house with a full set of sensor info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/barry/CodeAcademy/Ideal_dataset/coding/API/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from IdealDataInterface import IdealDataInterface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IdealMetadataInterface import IdealMetadataInterface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = '/Users/barry/CodeAcademy/Ideal_dataset/metadata_and_surveys/metadata'\n",
    "mdi = IdealMetadataInterface(folder_path)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### I want to be able to see all columns in a row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### make a DF with just the electric appliances in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found entries for 4824 sensor readings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ch/cdbcz7115ms5zvq6n9ds4wn00000gn/T/ipykernel_43984/601736614.py:14: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df = df.resample('1H').sum().round(2) #resample the data to 30 minute intervals as that is the grid's reconcilliation period (and is easier) and also rounding\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kettle</th>\n",
       "      <th>microwave</th>\n",
       "      <th>fridgefreezer</th>\n",
       "      <th>washingmachine</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-05-17 18:00:00</th>\n",
       "      <td>246</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-17 19:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-17 20:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-17 21:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-17 22:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-14 07:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-14 08:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-14 09:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-14 10:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-14 11:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9426 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     kettle  microwave  fridgefreezer  washingmachine\n",
       "time                                                                 \n",
       "2017-05-17 18:00:00     246        0.0            0.0             0.0\n",
       "2017-05-17 19:00:00       0        0.0            0.0             0.0\n",
       "2017-05-17 20:00:00       0        0.0            0.0             0.0\n",
       "2017-05-17 21:00:00       0        0.0            0.0             0.0\n",
       "2017-05-17 22:00:00       0        0.0            0.0             0.0\n",
       "...                     ...        ...            ...             ...\n",
       "2018-06-14 07:00:00       0        0.0            0.0             0.0\n",
       "2018-06-14 08:00:00       0        0.0            0.0             0.0\n",
       "2018-06-14 09:00:00       0        0.0            0.0             0.0\n",
       "2018-06-14 10:00:00       0        0.0            0.0             0.0\n",
       "2018-06-14 11:00:00       0        0.0            0.0             0.0\n",
       "\n",
       "[9426 rows x 4 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def df_appliance(homeid):\n",
    "    folder_path_appliances = '/Users/barry/CodeAcademy/Ideal_dataset/room_and_appliance_sensors/sensordata'\n",
    "    ideal_appliances = IdealDataInterface(folder_path_appliances)\n",
    "    view_df = ideal_appliances.view(homeid = homeid) #will allow us to get the sensorids\n",
    "    df = pd.DataFrame() #creat an empty dataframe to store the electric info\n",
    "    sensor_list = list(view_df[view_df.category == 'electric-appliance'].sensorid) #appliance sensor id's for the provided house\n",
    "    if len(sensor_list) > 0: #DF only gets populated if there are monitored appliances\n",
    "        electrics_appliance_info = ideal_appliances.get(sensorid = sensor_list) #appliance info as a list with extra infor\n",
    "        for appliance in electrics_appliance_info: #cycle through the list importing it to the dataframe\n",
    "            df[appliance['subtype']] = appliance['readings']\n",
    "    else:\n",
    "        print('no monitored appliances')\n",
    "    try:\n",
    "        df = df.resample('1H').sum().round(2) #resample the data to 30 minute intervals as that is the grid's reconcilliation period (and is easier) and also rounding\n",
    "        df = df.fillna(0) # get rid of the NaN values\n",
    "    except:\n",
    "        pass\n",
    "    return df\n",
    "df_appliance(106)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets get the main electric data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_dwelling(homeid):\n",
    "    folder_path_dwelling = '/Users/barry/CodeAcademy/Ideal_dataset/sensordata'\n",
    "    ideal_dwelling = IdealDataInterface(folder_path_dwelling)\n",
    "    sensor_list = list(ideal_dwelling.view(homeid = homeid).sensorid)\n",
    "    df_dwelling = pd.DataFrame() #creat an empty dataframe to store the electric info\n",
    "    dwelling_info = ideal_dwelling.get(sensorid = sensor_list)\n",
    "    if len(dwelling_info) > 0:\n",
    "        for sensor in dwelling_info:\n",
    "            df_dwelling[sensor['subtype']] = sensor['readings']\n",
    "    else:\n",
    "        print('no relevant dwelling sensors')\n",
    "    try:\n",
    "        df_dwelling = df_dwelling.resample('1H').sum().round(2) #resample the data to 30 minute intervals as that is the grid's reconcilliation period (and is easier) and also rounding\n",
    "        df_dwelling = df_dwelling.fillna(0) # get rid of the NaN values\n",
    "    except:\n",
    "        pass\n",
    "    return df_dwelling\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weather_getter(homeid): \n",
    "    folder_path = '/Users/barry/CodeAcademy/Ideal_dataset/metadata_and_surveys/metadata'\n",
    "    mdi = IdealMetadataInterface(folder_path)     \n",
    "    home_info = mdi.metadata.homes['home']\n",
    "    home_info = home_info[home_info.homeid == homeid]\n",
    "    home_info =home_info.reset_index()\n",
    "    weather_location = home_info.location.iloc[0]\n",
    "    print(weather_location)\n",
    "    if weather_location == 'Edinburgh':\n",
    "        weather_csv = pd.read_csv('/Users/barry/CodeAcademy/Ideal_dataset/Weather/edinburgh_weather.csv')\n",
    "        \n",
    "        weather_csv.columns = list(weather_csv.iloc[1])\n",
    "        weather_csv = weather_csv.iloc[2:,:]\n",
    "        weather_csv.set_index('time', inplace=True)\n",
    "        weather_csv.index = pd.to_datetime(weather_csv.index)\n",
    "    elif weather_location == 'Midlothian':\n",
    "        weather_csv = pd.read_csv('/Users/barry/CodeAcademy/Ideal_dataset/Weather/midlothian_weather.csv')\n",
    "        weather_csv.columns = list(weather_csv.iloc[1])\n",
    "        weather_csv = weather_csv.iloc[2:,:]\n",
    "        weather_csv.set_index('time', inplace=True)\n",
    "        weather_csv.index = pd.to_datetime(weather_csv.index)\n",
    "    elif weather_location == 'WestLothian':\n",
    "        weather_csv = pd.read_csv('/Users/barry/CodeAcademy/Ideal_dataset/Weather/westlothian_weather.csv')\n",
    "        weather_csv.columns = list(weather_csv.iloc[1])\n",
    "        weather_csv = weather_csv.iloc[2:,:]\n",
    "        weather_csv.set_index('time', inplace=True)\n",
    "        weather_csv.index = pd.to_datetime(weather_csv.index)\n",
    "    elif weather_location == 'EastLothian':\n",
    "        weather_csv = pd.read_csv('/Users/barry/CodeAcademy/Ideal_dataset/Weather/eastlothian_weather.csv')\n",
    "        weather_csv.columns = list(weather_csv.iloc[1])\n",
    "        weather_csv = weather_csv.iloc[2:,:]\n",
    "        weather_csv.set_index('time', inplace=True)\n",
    "        weather_csv.index = pd.to_datetime(weather_csv.index)\n",
    "    elif weather_location == 'Fife':\n",
    "        weather_csv = pd.read_csv('/Users/barry/CodeAcademy/Ideal_dataset/Weather/kirkcaldy_weather.csv')\n",
    "        weather_csv.columns = list(weather_csv.iloc[1])\n",
    "        weather_csv = weather_csv.iloc[2:,:]\n",
    "        weather_csv.set_index('time', inplace=True)\n",
    "        weather_csv.index = pd.to_datetime(weather_csv.index)\n",
    "    \n",
    "\n",
    "    else:\n",
    "        print('weather_location_wrong')\n",
    "    return weather_csv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Midlothian\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature_2m (°C)</th>\n",
       "      <th>relative_humidity_2m (%)</th>\n",
       "      <th>weather_code (wmo code)</th>\n",
       "      <th>wind_speed_10m (km/h)</th>\n",
       "      <th>wind_direction_10m (°)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-06-01 00:00:00</th>\n",
       "      <td>9.7</td>\n",
       "      <td>90</td>\n",
       "      <td>2</td>\n",
       "      <td>10.7</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-01 01:00:00</th>\n",
       "      <td>9.4</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>9.4</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-01 02:00:00</th>\n",
       "      <td>9.0</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>8.7</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-01 03:00:00</th>\n",
       "      <td>8.6</td>\n",
       "      <td>91</td>\n",
       "      <td>1</td>\n",
       "      <td>9.2</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-01 04:00:00</th>\n",
       "      <td>8.4</td>\n",
       "      <td>91</td>\n",
       "      <td>1</td>\n",
       "      <td>9.5</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-30 19:00:00</th>\n",
       "      <td>13.9</td>\n",
       "      <td>93</td>\n",
       "      <td>61</td>\n",
       "      <td>2.6</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-30 20:00:00</th>\n",
       "      <td>14.0</td>\n",
       "      <td>95</td>\n",
       "      <td>3</td>\n",
       "      <td>6.9</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-30 21:00:00</th>\n",
       "      <td>14.6</td>\n",
       "      <td>88</td>\n",
       "      <td>51</td>\n",
       "      <td>9.3</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-30 22:00:00</th>\n",
       "      <td>14.1</td>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-30 23:00:00</th>\n",
       "      <td>13.1</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18960 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    temperature_2m (°C) relative_humidity_2m (%)  \\\n",
       "time                                                               \n",
       "2016-06-01 00:00:00                 9.7                       90   \n",
       "2016-06-01 01:00:00                 9.4                       90   \n",
       "2016-06-01 02:00:00                 9.0                       90   \n",
       "2016-06-01 03:00:00                 8.6                       91   \n",
       "2016-06-01 04:00:00                 8.4                       91   \n",
       "...                                 ...                      ...   \n",
       "2018-07-30 19:00:00                13.9                       93   \n",
       "2018-07-30 20:00:00                14.0                       95   \n",
       "2018-07-30 21:00:00                14.6                       88   \n",
       "2018-07-30 22:00:00                14.1                       85   \n",
       "2018-07-30 23:00:00                13.1                       86   \n",
       "\n",
       "                    weather_code (wmo code) wind_speed_10m (km/h)  \\\n",
       "time                                                                \n",
       "2016-06-01 00:00:00                       2                  10.7   \n",
       "2016-06-01 01:00:00                       1                   9.4   \n",
       "2016-06-01 02:00:00                       1                   8.7   \n",
       "2016-06-01 03:00:00                       1                   9.2   \n",
       "2016-06-01 04:00:00                       1                   9.5   \n",
       "...                                     ...                   ...   \n",
       "2018-07-30 19:00:00                      61                   2.6   \n",
       "2018-07-30 20:00:00                       3                   6.9   \n",
       "2018-07-30 21:00:00                      51                   9.3   \n",
       "2018-07-30 22:00:00                       1                  12.0   \n",
       "2018-07-30 23:00:00                       0                  14.0   \n",
       "\n",
       "                    wind_direction_10m (°)  \n",
       "time                                        \n",
       "2016-06-01 00:00:00                     40  \n",
       "2016-06-01 01:00:00                     40  \n",
       "2016-06-01 02:00:00                     42  \n",
       "2016-06-01 03:00:00                     45  \n",
       "2016-06-01 04:00:00                     37  \n",
       "...                                    ...  \n",
       "2018-07-30 19:00:00                     34  \n",
       "2018-07-30 20:00:00                    219  \n",
       "2018-07-30 21:00:00                    234  \n",
       "2018-07-30 22:00:00                    219  \n",
       "2018-07-30 23:00:00                    209  \n",
       "\n",
       "[18960 rows x 5 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_getter(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### combining my DFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_combined(homeid):\n",
    "    df_app = df_appliance(homeid)\n",
    "    df_dw = df_dwelling(homeid)\n",
    "    df_weather = weather_getter(homeid)\n",
    "    df_combined = pd.concat([df_app, df_dw], axis = 1)\n",
    "    merged_df = df_combined.join(df_weather, how = 'inner')\n",
    "    \n",
    "    # merged_df.columns = ['kettle', 'microwave', 'fridgefreezer', 'washingmachine',\n",
    "    #    'hot-water-hot-pipe', 'hot-water-cold-pipe', 'gas', 'shower', 'mains',\n",
    "    #    'cooker', 'electric-combined', 'central-heating-flow',\n",
    "    #    'central-heating-return', 'temperature_2m',\n",
    "    #    'relative_humidity_2m', 'weather_code',\n",
    "    #    'wind_speed', 'wind_direction']\n",
    "    merged_df['electric-combined'] = merged_df['electric-combined'].apply(lambda x: x / 3600)\n",
    "    merged_df['electric-combined'] = merged_df['electric-combined'].round(2)\n",
    "    merged_df['electric_combined_1h_forecast'] = merged_df['electric-combined'].shift(-1)\n",
    "    merged_df['day'] = merged_df.index.weekday\n",
    "    merged_df['hour']= merged_df.index.hour\n",
    "    if 'mains' in merged_df.columns:\n",
    "        first_non_zero = merged_df['mains'].ne(0).idxmax()\n",
    "        merged_df = merged_df.loc[first_non_zero:]\n",
    "    else:\n",
    "        pass\n",
    "    merged_df = merged_df.iloc[5:]\n",
    "    first_non_zero = merged_df['electric-combined'].ne(0).idxmax()\n",
    "    # I need my measurements to be in Wh so i need to multiply them by 3600\n",
    "\n",
    "\n",
    "    merged_df['electric_combined_1W_lagged'] = merged_df['electric-combined'].shift(168)\n",
    "\n",
    "    merged_df = merged_df.loc[first_non_zero:]\n",
    "\n",
    "    col_to_move = merged_df.pop('electric-combined')\n",
    "    merged_df['electric-combined'] = col_to_move\n",
    "\n",
    "\n",
    "    col_to_move = merged_df.pop('electric_combined_1h_forecast')\n",
    "    merged_df['electric_combined_1h_forecast'] = col_to_move\n",
    "\n",
    "    if os.path.exists(f'/Users/barry/CodeAcademy/Ideal_dataset/updated_hourly_csv/hourly_{homeid}.csv'):\n",
    "        print(f'file already exists for {homeid}')\n",
    "    else:\n",
    "        merged_df.to_csv(f'/Users/barry/CodeAcademy/Ideal_dataset/updated_hourly_csv/hourly_{homeid}.csv')\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# to get the list of enhanced houses only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IdealMetadataInterface import IdealMetadataInterface\n",
    "folder_path2 = '/Users/barry/CodeAcademy/Ideal_dataset/metadata_and_surveys/metadata'\n",
    "metadata = IdealMetadataInterface(folder_path2)\n",
    "full_list = metadata.metadata.homes['home']\n",
    "enhanced_houses = list(full_list[full_list.install_type == 'enhanced'].homeid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found entries for 4824 sensor readings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ch/cdbcz7115ms5zvq6n9ds4wn00000gn/T/ipykernel_43984/601736614.py:14: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df = df.resample('1H').sum().round(2) #resample the data to 30 minute intervals as that is the grid's reconcilliation period (and is easier) and also rounding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found entries for 1592 sensor readings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ch/cdbcz7115ms5zvq6n9ds4wn00000gn/T/ipykernel_43984/2682361694.py:13: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df_dwelling = df_dwelling.resample('1H').sum().round(2) #resample the data to 30 minute intervals as that is the grid's reconcilliation period (and is easier) and also rounding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edinburgh\n",
      "Found entries for 4824 sensor readings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ch/cdbcz7115ms5zvq6n9ds4wn00000gn/T/ipykernel_43984/601736614.py:14: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df = df.resample('1H').sum().round(2) #resample the data to 30 minute intervals as that is the grid's reconcilliation period (and is easier) and also rounding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found entries for 1592 sensor readings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ch/cdbcz7115ms5zvq6n9ds4wn00000gn/T/ipykernel_43984/2682361694.py:13: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df_dwelling = df_dwelling.resample('1H').sum().round(2) #resample the data to 30 minute intervals as that is the grid's reconcilliation period (and is easier) and also rounding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edinburgh\n",
      "Found entries for 4824 sensor readings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ch/cdbcz7115ms5zvq6n9ds4wn00000gn/T/ipykernel_43984/601736614.py:14: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df = df.resample('1H').sum().round(2) #resample the data to 30 minute intervals as that is the grid's reconcilliation period (and is easier) and also rounding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found entries for 1592 sensor readings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ch/cdbcz7115ms5zvq6n9ds4wn00000gn/T/ipykernel_43984/2682361694.py:13: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df_dwelling = df_dwelling.resample('1H').sum().round(2) #resample the data to 30 minute intervals as that is the grid's reconcilliation period (and is easier) and also rounding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edinburgh\n",
      "Found entries for 4824 sensor readings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ch/cdbcz7115ms5zvq6n9ds4wn00000gn/T/ipykernel_43984/601736614.py:14: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df = df.resample('1H').sum().round(2) #resample the data to 30 minute intervals as that is the grid's reconcilliation period (and is easier) and also rounding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found entries for 1592 sensor readings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ch/cdbcz7115ms5zvq6n9ds4wn00000gn/T/ipykernel_43984/2682361694.py:13: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df_dwelling = df_dwelling.resample('1H').sum().round(2) #resample the data to 30 minute intervals as that is the grid's reconcilliation period (and is easier) and also rounding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edinburgh\n",
      "Found entries for 4824 sensor readings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ch/cdbcz7115ms5zvq6n9ds4wn00000gn/T/ipykernel_43984/601736614.py:14: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df = df.resample('1H').sum().round(2) #resample the data to 30 minute intervals as that is the grid's reconcilliation period (and is easier) and also rounding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found entries for 1592 sensor readings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ch/cdbcz7115ms5zvq6n9ds4wn00000gn/T/ipykernel_43984/2682361694.py:13: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df_dwelling = df_dwelling.resample('1H').sum().round(2) #resample the data to 30 minute intervals as that is the grid's reconcilliation period (and is easier) and also rounding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Midlothian\n",
      "Found entries for 4824 sensor readings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ch/cdbcz7115ms5zvq6n9ds4wn00000gn/T/ipykernel_43984/601736614.py:14: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df = df.resample('1H').sum().round(2) #resample the data to 30 minute intervals as that is the grid's reconcilliation period (and is easier) and also rounding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found entries for 1592 sensor readings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ch/cdbcz7115ms5zvq6n9ds4wn00000gn/T/ipykernel_43984/2682361694.py:13: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df_dwelling = df_dwelling.resample('1H').sum().round(2) #resample the data to 30 minute intervals as that is the grid's reconcilliation period (and is easier) and also rounding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edinburgh\n",
      "Found entries for 4824 sensor readings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ch/cdbcz7115ms5zvq6n9ds4wn00000gn/T/ipykernel_43984/601736614.py:14: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df = df.resample('1H').sum().round(2) #resample the data to 30 minute intervals as that is the grid's reconcilliation period (and is easier) and also rounding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found entries for 1592 sensor readings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ch/cdbcz7115ms5zvq6n9ds4wn00000gn/T/ipykernel_43984/2682361694.py:13: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df_dwelling = df_dwelling.resample('1H').sum().round(2) #resample the data to 30 minute intervals as that is the grid's reconcilliation period (and is easier) and also rounding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Midlothian\n",
      "Found entries for 4824 sensor readings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ch/cdbcz7115ms5zvq6n9ds4wn00000gn/T/ipykernel_43984/601736614.py:14: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df = df.resample('1H').sum().round(2) #resample the data to 30 minute intervals as that is the grid's reconcilliation period (and is easier) and also rounding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found entries for 1592 sensor readings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ch/cdbcz7115ms5zvq6n9ds4wn00000gn/T/ipykernel_43984/2682361694.py:13: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df_dwelling = df_dwelling.resample('1H').sum().round(2) #resample the data to 30 minute intervals as that is the grid's reconcilliation period (and is easier) and also rounding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edinburgh\n",
      "Found entries for 4824 sensor readings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ch/cdbcz7115ms5zvq6n9ds4wn00000gn/T/ipykernel_43984/601736614.py:14: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df = df.resample('1H').sum().round(2) #resample the data to 30 minute intervals as that is the grid's reconcilliation period (and is easier) and also rounding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found entries for 1592 sensor readings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ch/cdbcz7115ms5zvq6n9ds4wn00000gn/T/ipykernel_43984/2682361694.py:13: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df_dwelling = df_dwelling.resample('1H').sum().round(2) #resample the data to 30 minute intervals as that is the grid's reconcilliation period (and is easier) and also rounding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edinburgh\n",
      "Found entries for 4824 sensor readings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ch/cdbcz7115ms5zvq6n9ds4wn00000gn/T/ipykernel_43984/601736614.py:14: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df = df.resample('1H').sum().round(2) #resample the data to 30 minute intervals as that is the grid's reconcilliation period (and is easier) and also rounding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found entries for 1592 sensor readings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ch/cdbcz7115ms5zvq6n9ds4wn00000gn/T/ipykernel_43984/2682361694.py:13: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df_dwelling = df_dwelling.resample('1H').sum().round(2) #resample the data to 30 minute intervals as that is the grid's reconcilliation period (and is easier) and also rounding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edinburgh\n",
      "Found entries for 4824 sensor readings.\n",
      "Found entries for 1592 sensor readings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ch/cdbcz7115ms5zvq6n9ds4wn00000gn/T/ipykernel_43984/601736614.py:14: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df = df.resample('1H').sum().round(2) #resample the data to 30 minute intervals as that is the grid's reconcilliation period (and is easier) and also rounding\n",
      "/var/folders/ch/cdbcz7115ms5zvq6n9ds4wn00000gn/T/ipykernel_43984/2682361694.py:13: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df_dwelling = df_dwelling.resample('1H').sum().round(2) #resample the data to 30 minute intervals as that is the grid's reconcilliation period (and is easier) and also rounding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edinburgh\n",
      "Found entries for 4824 sensor readings.\n",
      "Found entries for 1592 sensor readings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ch/cdbcz7115ms5zvq6n9ds4wn00000gn/T/ipykernel_43984/601736614.py:14: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df = df.resample('1H').sum().round(2) #resample the data to 30 minute intervals as that is the grid's reconcilliation period (and is easier) and also rounding\n",
      "/var/folders/ch/cdbcz7115ms5zvq6n9ds4wn00000gn/T/ipykernel_43984/2682361694.py:13: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df_dwelling = df_dwelling.resample('1H').sum().round(2) #resample the data to 30 minute intervals as that is the grid's reconcilliation period (and is easier) and also rounding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edinburgh\n",
      "Found entries for 4824 sensor readings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ch/cdbcz7115ms5zvq6n9ds4wn00000gn/T/ipykernel_43984/601736614.py:14: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df = df.resample('1H').sum().round(2) #resample the data to 30 minute intervals as that is the grid's reconcilliation period (and is easier) and also rounding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found entries for 1592 sensor readings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ch/cdbcz7115ms5zvq6n9ds4wn00000gn/T/ipykernel_43984/2682361694.py:13: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df_dwelling = df_dwelling.resample('1H').sum().round(2) #resample the data to 30 minute intervals as that is the grid's reconcilliation period (and is easier) and also rounding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Midlothian\n",
      "Found entries for 4824 sensor readings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ch/cdbcz7115ms5zvq6n9ds4wn00000gn/T/ipykernel_43984/601736614.py:14: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df = df.resample('1H').sum().round(2) #resample the data to 30 minute intervals as that is the grid's reconcilliation period (and is easier) and also rounding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found entries for 1592 sensor readings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ch/cdbcz7115ms5zvq6n9ds4wn00000gn/T/ipykernel_43984/2682361694.py:13: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df_dwelling = df_dwelling.resample('1H').sum().round(2) #resample the data to 30 minute intervals as that is the grid's reconcilliation period (and is easier) and also rounding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WestLothian\n",
      "Found entries for 4824 sensor readings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ch/cdbcz7115ms5zvq6n9ds4wn00000gn/T/ipykernel_43984/601736614.py:14: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df = df.resample('1H').sum().round(2) #resample the data to 30 minute intervals as that is the grid's reconcilliation period (and is easier) and also rounding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found entries for 1592 sensor readings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ch/cdbcz7115ms5zvq6n9ds4wn00000gn/T/ipykernel_43984/2682361694.py:13: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df_dwelling = df_dwelling.resample('1H').sum().round(2) #resample the data to 30 minute intervals as that is the grid's reconcilliation period (and is easier) and also rounding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WestLothian\n",
      "Found entries for 4824 sensor readings.\n",
      "Found entries for 1592 sensor readings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ch/cdbcz7115ms5zvq6n9ds4wn00000gn/T/ipykernel_43984/601736614.py:14: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df = df.resample('1H').sum().round(2) #resample the data to 30 minute intervals as that is the grid's reconcilliation period (and is easier) and also rounding\n",
      "/var/folders/ch/cdbcz7115ms5zvq6n9ds4wn00000gn/T/ipykernel_43984/2682361694.py:13: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df_dwelling = df_dwelling.resample('1H').sum().round(2) #resample the data to 30 minute intervals as that is the grid's reconcilliation period (and is easier) and also rounding\n",
      "/var/folders/ch/cdbcz7115ms5zvq6n9ds4wn00000gn/T/ipykernel_43984/601736614.py:14: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df = df.resample('1H').sum().round(2) #resample the data to 30 minute intervals as that is the grid's reconcilliation period (and is easier) and also rounding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edinburgh\n",
      "Found entries for 4824 sensor readings.\n",
      "Found entries for 1592 sensor readings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ch/cdbcz7115ms5zvq6n9ds4wn00000gn/T/ipykernel_43984/2682361694.py:13: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df_dwelling = df_dwelling.resample('1H').sum().round(2) #resample the data to 30 minute intervals as that is the grid's reconcilliation period (and is easier) and also rounding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edinburgh\n",
      "Found entries for 4824 sensor readings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ch/cdbcz7115ms5zvq6n9ds4wn00000gn/T/ipykernel_43984/601736614.py:14: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df = df.resample('1H').sum().round(2) #resample the data to 30 minute intervals as that is the grid's reconcilliation period (and is easier) and also rounding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found entries for 1592 sensor readings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ch/cdbcz7115ms5zvq6n9ds4wn00000gn/T/ipykernel_43984/2682361694.py:13: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df_dwelling = df_dwelling.resample('1H').sum().round(2) #resample the data to 30 minute intervals as that is the grid's reconcilliation period (and is easier) and also rounding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Midlothian\n",
      "Found entries for 4824 sensor readings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ch/cdbcz7115ms5zvq6n9ds4wn00000gn/T/ipykernel_43984/601736614.py:14: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df = df.resample('1H').sum().round(2) #resample the data to 30 minute intervals as that is the grid's reconcilliation period (and is easier) and also rounding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found entries for 1592 sensor readings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ch/cdbcz7115ms5zvq6n9ds4wn00000gn/T/ipykernel_43984/2682361694.py:13: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df_dwelling = df_dwelling.resample('1H').sum().round(2) #resample the data to 30 minute intervals as that is the grid's reconcilliation period (and is easier) and also rounding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edinburgh\n",
      "Found entries for 4824 sensor readings.\n",
      "Found entries for 1592 sensor readings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ch/cdbcz7115ms5zvq6n9ds4wn00000gn/T/ipykernel_43984/601736614.py:14: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df = df.resample('1H').sum().round(2) #resample the data to 30 minute intervals as that is the grid's reconcilliation period (and is easier) and also rounding\n",
      "/var/folders/ch/cdbcz7115ms5zvq6n9ds4wn00000gn/T/ipykernel_43984/2682361694.py:13: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df_dwelling = df_dwelling.resample('1H').sum().round(2) #resample the data to 30 minute intervals as that is the grid's reconcilliation period (and is easier) and also rounding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EastLothian\n",
      "Found entries for 4824 sensor readings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ch/cdbcz7115ms5zvq6n9ds4wn00000gn/T/ipykernel_43984/601736614.py:14: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df = df.resample('1H').sum().round(2) #resample the data to 30 minute intervals as that is the grid's reconcilliation period (and is easier) and also rounding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found entries for 1592 sensor readings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ch/cdbcz7115ms5zvq6n9ds4wn00000gn/T/ipykernel_43984/2682361694.py:13: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df_dwelling = df_dwelling.resample('1H').sum().round(2) #resample the data to 30 minute intervals as that is the grid's reconcilliation period (and is easier) and also rounding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edinburgh\n",
      "Found entries for 4824 sensor readings.\n",
      "Found entries for 1592 sensor readings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ch/cdbcz7115ms5zvq6n9ds4wn00000gn/T/ipykernel_43984/601736614.py:14: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df = df.resample('1H').sum().round(2) #resample the data to 30 minute intervals as that is the grid's reconcilliation period (and is easier) and also rounding\n",
      "/var/folders/ch/cdbcz7115ms5zvq6n9ds4wn00000gn/T/ipykernel_43984/2682361694.py:13: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df_dwelling = df_dwelling.resample('1H').sum().round(2) #resample the data to 30 minute intervals as that is the grid's reconcilliation period (and is easier) and also rounding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edinburgh\n",
      "Found entries for 4824 sensor readings.\n",
      "Found entries for 1592 sensor readings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ch/cdbcz7115ms5zvq6n9ds4wn00000gn/T/ipykernel_43984/601736614.py:14: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df = df.resample('1H').sum().round(2) #resample the data to 30 minute intervals as that is the grid's reconcilliation period (and is easier) and also rounding\n",
      "/var/folders/ch/cdbcz7115ms5zvq6n9ds4wn00000gn/T/ipykernel_43984/2682361694.py:13: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df_dwelling = df_dwelling.resample('1H').sum().round(2) #resample the data to 30 minute intervals as that is the grid's reconcilliation period (and is easier) and also rounding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edinburgh\n",
      "Found entries for 4824 sensor readings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ch/cdbcz7115ms5zvq6n9ds4wn00000gn/T/ipykernel_43984/601736614.py:14: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df = df.resample('1H').sum().round(2) #resample the data to 30 minute intervals as that is the grid's reconcilliation period (and is easier) and also rounding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found entries for 1592 sensor readings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ch/cdbcz7115ms5zvq6n9ds4wn00000gn/T/ipykernel_43984/2682361694.py:13: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df_dwelling = df_dwelling.resample('1H').sum().round(2) #resample the data to 30 minute intervals as that is the grid's reconcilliation period (and is easier) and also rounding\n",
      "/var/folders/ch/cdbcz7115ms5zvq6n9ds4wn00000gn/T/ipykernel_43984/601736614.py:14: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df = df.resample('1H').sum().round(2) #resample the data to 30 minute intervals as that is the grid's reconcilliation period (and is easier) and also rounding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Midlothian\n",
      "Found entries for 4824 sensor readings.\n",
      "Found entries for 1592 sensor readings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ch/cdbcz7115ms5zvq6n9ds4wn00000gn/T/ipykernel_43984/2682361694.py:13: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df_dwelling = df_dwelling.resample('1H').sum().round(2) #resample the data to 30 minute intervals as that is the grid's reconcilliation period (and is easier) and also rounding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edinburgh\n",
      "Found entries for 4824 sensor readings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ch/cdbcz7115ms5zvq6n9ds4wn00000gn/T/ipykernel_43984/601736614.py:14: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df = df.resample('1H').sum().round(2) #resample the data to 30 minute intervals as that is the grid's reconcilliation period (and is easier) and also rounding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found entries for 1592 sensor readings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ch/cdbcz7115ms5zvq6n9ds4wn00000gn/T/ipykernel_43984/2682361694.py:13: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df_dwelling = df_dwelling.resample('1H').sum().round(2) #resample the data to 30 minute intervals as that is the grid's reconcilliation period (and is easier) and also rounding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edinburgh\n",
      "Found entries for 4824 sensor readings.\n",
      "Found entries for 1592 sensor readings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ch/cdbcz7115ms5zvq6n9ds4wn00000gn/T/ipykernel_43984/601736614.py:14: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df = df.resample('1H').sum().round(2) #resample the data to 30 minute intervals as that is the grid's reconcilliation period (and is easier) and also rounding\n",
      "/var/folders/ch/cdbcz7115ms5zvq6n9ds4wn00000gn/T/ipykernel_43984/2682361694.py:13: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df_dwelling = df_dwelling.resample('1H').sum().round(2) #resample the data to 30 minute intervals as that is the grid's reconcilliation period (and is easier) and also rounding\n",
      "/var/folders/ch/cdbcz7115ms5zvq6n9ds4wn00000gn/T/ipykernel_43984/601736614.py:14: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df = df.resample('1H').sum().round(2) #resample the data to 30 minute intervals as that is the grid's reconcilliation period (and is easier) and also rounding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edinburgh\n",
      "Found entries for 4824 sensor readings.\n",
      "Found entries for 1592 sensor readings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ch/cdbcz7115ms5zvq6n9ds4wn00000gn/T/ipykernel_43984/2682361694.py:13: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df_dwelling = df_dwelling.resample('1H').sum().round(2) #resample the data to 30 minute intervals as that is the grid's reconcilliation period (and is easier) and also rounding\n",
      "/var/folders/ch/cdbcz7115ms5zvq6n9ds4wn00000gn/T/ipykernel_43984/601736614.py:14: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df = df.resample('1H').sum().round(2) #resample the data to 30 minute intervals as that is the grid's reconcilliation period (and is easier) and also rounding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edinburgh\n",
      "Found entries for 4824 sensor readings.\n",
      "Found entries for 1592 sensor readings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ch/cdbcz7115ms5zvq6n9ds4wn00000gn/T/ipykernel_43984/2682361694.py:13: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df_dwelling = df_dwelling.resample('1H').sum().round(2) #resample the data to 30 minute intervals as that is the grid's reconcilliation period (and is easier) and also rounding\n",
      "/var/folders/ch/cdbcz7115ms5zvq6n9ds4wn00000gn/T/ipykernel_43984/601736614.py:14: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df = df.resample('1H').sum().round(2) #resample the data to 30 minute intervals as that is the grid's reconcilliation period (and is easier) and also rounding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edinburgh\n",
      "Found entries for 4824 sensor readings.\n",
      "Found entries for 1592 sensor readings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ch/cdbcz7115ms5zvq6n9ds4wn00000gn/T/ipykernel_43984/2682361694.py:13: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df_dwelling = df_dwelling.resample('1H').sum().round(2) #resample the data to 30 minute intervals as that is the grid's reconcilliation period (and is easier) and also rounding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edinburgh\n",
      "Found entries for 4824 sensor readings.\n",
      "Found entries for 1592 sensor readings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ch/cdbcz7115ms5zvq6n9ds4wn00000gn/T/ipykernel_43984/601736614.py:14: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df = df.resample('1H').sum().round(2) #resample the data to 30 minute intervals as that is the grid's reconcilliation period (and is easier) and also rounding\n",
      "/var/folders/ch/cdbcz7115ms5zvq6n9ds4wn00000gn/T/ipykernel_43984/2682361694.py:13: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df_dwelling = df_dwelling.resample('1H').sum().round(2) #resample the data to 30 minute intervals as that is the grid's reconcilliation period (and is easier) and also rounding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fife\n",
      "Found entries for 4824 sensor readings.\n",
      "Found entries for 1592 sensor readings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ch/cdbcz7115ms5zvq6n9ds4wn00000gn/T/ipykernel_43984/601736614.py:14: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df = df.resample('1H').sum().round(2) #resample the data to 30 minute intervals as that is the grid's reconcilliation period (and is easier) and also rounding\n",
      "/var/folders/ch/cdbcz7115ms5zvq6n9ds4wn00000gn/T/ipykernel_43984/2682361694.py:13: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df_dwelling = df_dwelling.resample('1H').sum().round(2) #resample the data to 30 minute intervals as that is the grid's reconcilliation period (and is easier) and also rounding\n",
      "/var/folders/ch/cdbcz7115ms5zvq6n9ds4wn00000gn/T/ipykernel_43984/601736614.py:14: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df = df.resample('1H').sum().round(2) #resample the data to 30 minute intervals as that is the grid's reconcilliation period (and is easier) and also rounding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edinburgh\n",
      "Found entries for 4824 sensor readings.\n",
      "Found entries for 1592 sensor readings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ch/cdbcz7115ms5zvq6n9ds4wn00000gn/T/ipykernel_43984/2682361694.py:13: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df_dwelling = df_dwelling.resample('1H').sum().round(2) #resample the data to 30 minute intervals as that is the grid's reconcilliation period (and is easier) and also rounding\n",
      "/var/folders/ch/cdbcz7115ms5zvq6n9ds4wn00000gn/T/ipykernel_43984/601736614.py:14: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df = df.resample('1H').sum().round(2) #resample the data to 30 minute intervals as that is the grid's reconcilliation period (and is easier) and also rounding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fife\n",
      "Found entries for 4824 sensor readings.\n",
      "Found entries for 1592 sensor readings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ch/cdbcz7115ms5zvq6n9ds4wn00000gn/T/ipykernel_43984/2682361694.py:13: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df_dwelling = df_dwelling.resample('1H').sum().round(2) #resample the data to 30 minute intervals as that is the grid's reconcilliation period (and is easier) and also rounding\n",
      "/var/folders/ch/cdbcz7115ms5zvq6n9ds4wn00000gn/T/ipykernel_43984/601736614.py:14: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df = df.resample('1H').sum().round(2) #resample the data to 30 minute intervals as that is the grid's reconcilliation period (and is easier) and also rounding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Midlothian\n",
      "Found entries for 4824 sensor readings.\n",
      "Found entries for 1592 sensor readings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ch/cdbcz7115ms5zvq6n9ds4wn00000gn/T/ipykernel_43984/2682361694.py:13: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df_dwelling = df_dwelling.resample('1H').sum().round(2) #resample the data to 30 minute intervals as that is the grid's reconcilliation period (and is easier) and also rounding\n",
      "/var/folders/ch/cdbcz7115ms5zvq6n9ds4wn00000gn/T/ipykernel_43984/601736614.py:14: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df = df.resample('1H').sum().round(2) #resample the data to 30 minute intervals as that is the grid's reconcilliation period (and is easier) and also rounding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edinburgh\n",
      "Found entries for 4824 sensor readings.\n",
      "Found entries for 1592 sensor readings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ch/cdbcz7115ms5zvq6n9ds4wn00000gn/T/ipykernel_43984/2682361694.py:13: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df_dwelling = df_dwelling.resample('1H').sum().round(2) #resample the data to 30 minute intervals as that is the grid's reconcilliation period (and is easier) and also rounding\n",
      "/var/folders/ch/cdbcz7115ms5zvq6n9ds4wn00000gn/T/ipykernel_43984/601736614.py:14: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df = df.resample('1H').sum().round(2) #resample the data to 30 minute intervals as that is the grid's reconcilliation period (and is easier) and also rounding\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edinburgh\n",
      "Found entries for 4824 sensor readings.\n",
      "Found entries for 1592 sensor readings.\n",
      "Edinburgh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ch/cdbcz7115ms5zvq6n9ds4wn00000gn/T/ipykernel_43984/2682361694.py:13: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df_dwelling = df_dwelling.resample('1H').sum().round(2) #resample the data to 30 minute intervals as that is the grid's reconcilliation period (and is easier) and also rounding\n"
     ]
    }
   ],
   "source": [
    "for house in enhanced_houses[2:]:\n",
    "    df_combined(house)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found entries for 4824 sensor readings.\n",
      "Found entries for 1592 sensor readings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ch/cdbcz7115ms5zvq6n9ds4wn00000gn/T/ipykernel_43984/601736614.py:14: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df = df.resample('1H').sum().round(2) #resample the data to 30 minute intervals as that is the grid's reconcilliation period (and is easier) and also rounding\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_combined(\u001b[38;5;241m106\u001b[39m)\n",
      "Cell \u001b[0;32mIn[32], line 3\u001b[0m, in \u001b[0;36mdf_combined\u001b[0;34m(homeid)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdf_combined\u001b[39m(homeid):\n\u001b[1;32m      2\u001b[0m     df_app \u001b[38;5;241m=\u001b[39m df_appliance(homeid)\n\u001b[0;32m----> 3\u001b[0m     df_dw \u001b[38;5;241m=\u001b[39m df_dwelling(homeid)\n\u001b[1;32m      4\u001b[0m     df_weather \u001b[38;5;241m=\u001b[39m weather_getter(homeid)\n\u001b[1;32m      5\u001b[0m     df_combined \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df_app, df_dw], axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn[29], line 6\u001b[0m, in \u001b[0;36mdf_dwelling\u001b[0;34m(homeid)\u001b[0m\n\u001b[1;32m      4\u001b[0m sensor_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ideal_dwelling\u001b[38;5;241m.\u001b[39mview(homeid \u001b[38;5;241m=\u001b[39m homeid)\u001b[38;5;241m.\u001b[39msensorid)\n\u001b[1;32m      5\u001b[0m df_dwelling \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame() \u001b[38;5;66;03m#creat an empty dataframe to store the electric info\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m dwelling_info \u001b[38;5;241m=\u001b[39m ideal_dwelling\u001b[38;5;241m.\u001b[39mget(sensorid \u001b[38;5;241m=\u001b[39m sensor_list)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(dwelling_info) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m sensor \u001b[38;5;129;01min\u001b[39;00m dwelling_info:\n",
      "File \u001b[0;32m~/CodeAcademy/Ideal_dataset/coding/API/IdealDataInterface.py:160\u001b[0m, in \u001b[0;36mIdealDataInterface.get\u001b[0;34m(self, homeid, roomid, room_type, category, subtype, sensorid)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (homeid, roomid, room_type, category, subtype, sensorid), row \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m    158\u001b[0m     fname \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfolder_path \u001b[38;5;241m/\u001b[39m Path(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfilename\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m--> 160\u001b[0m     ts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread_csv_(fname, subtype\u001b[38;5;241m=\u001b[39msubtype)\n\u001b[1;32m    162\u001b[0m     readings\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhomeid\u001b[39m\u001b[38;5;124m'\u001b[39m: homeid, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroomid\u001b[39m\u001b[38;5;124m'\u001b[39m: roomid, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroom_type\u001b[39m\u001b[38;5;124m'\u001b[39m: room_type,\n\u001b[1;32m    163\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m'\u001b[39m: category, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubtype\u001b[39m\u001b[38;5;124m'\u001b[39m: subtype, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msensorid\u001b[39m\u001b[38;5;124m'\u001b[39m: sensorid,\n\u001b[1;32m    164\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreadings\u001b[39m\u001b[38;5;124m'\u001b[39m: ts})\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m readings\n",
      "File \u001b[0;32m~/CodeAcademy/Ideal_dataset/coding/API/IdealDataInterface.py:123\u001b[0m, in \u001b[0;36mIdealDataInterface.read_csv_\u001b[0;34m(self, fname, subtype)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_csv_\u001b[39m(\u001b[38;5;28mself\u001b[39m, fname, subtype):\n\u001b[1;32m    122\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" Load the file to pandas DataFrame. \"\"\"\u001b[39;00m\n\u001b[0;32m--> 123\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(fname, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, names\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m], parse_dates\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;66;03m# Sanity check make sure the date\u001b[39;00m\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39missubdtype(df\u001b[38;5;241m.\u001b[39mdtypes[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m], np\u001b[38;5;241m.\u001b[39mdatetime64)\n",
      "File \u001b[0;32m~/anaconda3/envs/IdealDataInterface/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/anaconda3/envs/IdealDataInterface/lib/python3.11/site-packages/pandas/io/parsers/readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\u001b[38;5;241m.\u001b[39mread(nrows)\n",
      "File \u001b[0;32m~/anaconda3/envs/IdealDataInterface/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1923\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1916\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1917\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1918\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1919\u001b[0m     (\n\u001b[1;32m   1920\u001b[0m         index,\n\u001b[1;32m   1921\u001b[0m         columns,\n\u001b[1;32m   1922\u001b[0m         col_dict,\n\u001b[0;32m-> 1923\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mread(  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m         nrows\n\u001b[1;32m   1925\u001b[0m     )\n\u001b[1;32m   1926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/anaconda3/envs/IdealDataInterface/lib/python3.11/site-packages/pandas/io/parsers/c_parser_wrapper.py:332\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_data_length(names, alldata)\n\u001b[1;32m    330\u001b[0m     data \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, (i, v) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(names, data_tups)}\n\u001b[0;32m--> 332\u001b[0m     names, date_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_date_conversions(names, data)\n\u001b[1;32m    333\u001b[0m     index, column_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_index(date_data, alldata, names)\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m index, column_names, date_data\n",
      "File \u001b[0;32m~/anaconda3/envs/IdealDataInterface/lib/python3.11/site-packages/pandas/io/parsers/base_parser.py:880\u001b[0m, in \u001b[0;36mParserBase._do_date_conversions\u001b[0;34m(self, names, data)\u001b[0m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m    872\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_do_date_conversions\u001b[39m(\n\u001b[1;32m    873\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    876\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[Sequence[Hashable] \u001b[38;5;241m|\u001b[39m Index, Mapping[Hashable, ArrayLike] \u001b[38;5;241m|\u001b[39m DataFrame]:\n\u001b[1;32m    877\u001b[0m     \u001b[38;5;66;03m# returns data, columns\u001b[39;00m\n\u001b[1;32m    879\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_dates \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 880\u001b[0m         data, names \u001b[38;5;241m=\u001b[39m _process_date_conversion(\n\u001b[1;32m    881\u001b[0m             data,\n\u001b[1;32m    882\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_date_conv,\n\u001b[1;32m    883\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_dates,\n\u001b[1;32m    884\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex_col,\n\u001b[1;32m    885\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex_names,\n\u001b[1;32m    886\u001b[0m             names,\n\u001b[1;32m    887\u001b[0m             keep_date_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeep_date_col,\n\u001b[1;32m    888\u001b[0m             dtype_backend\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype_backend,\n\u001b[1;32m    889\u001b[0m         )\n\u001b[1;32m    891\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m names, data\n",
      "File \u001b[0;32m~/anaconda3/envs/IdealDataInterface/lib/python3.11/site-packages/pandas/io/parsers/base_parser.py:1315\u001b[0m, in \u001b[0;36m_process_date_conversion\u001b[0;34m(data_dict, converter, parse_spec, index_col, index_names, columns, keep_date_col, dtype_backend)\u001b[0m\n\u001b[1;32m   1311\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1313\u001b[0m     \u001b[38;5;66;03m# Pyarrow engine returns Series which we need to convert to\u001b[39;00m\n\u001b[1;32m   1314\u001b[0m     \u001b[38;5;66;03m# numpy array before converter, its a no-op for other parsers\u001b[39;00m\n\u001b[0;32m-> 1315\u001b[0m     data_dict[colspec] \u001b[38;5;241m=\u001b[39m converter(\n\u001b[1;32m   1316\u001b[0m         np\u001b[38;5;241m.\u001b[39masarray(data_dict[colspec]), col\u001b[38;5;241m=\u001b[39mcolspec\n\u001b[1;32m   1317\u001b[0m     )\n\u001b[1;32m   1318\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1319\u001b[0m     new_name, col, old_names \u001b[38;5;241m=\u001b[39m _try_convert_dates(\n\u001b[1;32m   1320\u001b[0m         converter, colspec, data_dict, orig_names\n\u001b[1;32m   1321\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/IdealDataInterface/lib/python3.11/site-packages/pandas/io/parsers/base_parser.py:1165\u001b[0m, in \u001b[0;36m_make_date_converter.<locals>.converter\u001b[0;34m(col, *date_cols)\u001b[0m\n\u001b[1;32m   1163\u001b[0m str_objs \u001b[38;5;241m=\u001b[39m ensure_object(strs)\n\u001b[1;32m   1164\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1165\u001b[0m     result \u001b[38;5;241m=\u001b[39m tools\u001b[38;5;241m.\u001b[39mto_datetime(\n\u001b[1;32m   1166\u001b[0m         str_objs,\n\u001b[1;32m   1167\u001b[0m         \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39mdate_fmt,\n\u001b[1;32m   1168\u001b[0m         utc\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1169\u001b[0m         dayfirst\u001b[38;5;241m=\u001b[39mdayfirst,\n\u001b[1;32m   1170\u001b[0m         cache\u001b[38;5;241m=\u001b[39mcache_dates,\n\u001b[1;32m   1171\u001b[0m     )\n\u001b[1;32m   1172\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[1;32m   1173\u001b[0m     \u001b[38;5;66;03m# test_usecols_with_parse_dates4\u001b[39;00m\n\u001b[1;32m   1174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m str_objs\n",
      "File \u001b[0;32m~/anaconda3/envs/IdealDataInterface/lib/python3.11/site-packages/pandas/core/tools/datetimes.py:1099\u001b[0m, in \u001b[0;36mto_datetime\u001b[0;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[1;32m   1097\u001b[0m         result \u001b[38;5;241m=\u001b[39m _convert_and_box_cache(argc, cache_array)\n\u001b[1;32m   1098\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1099\u001b[0m         result \u001b[38;5;241m=\u001b[39m convert_listlike(argc, \u001b[38;5;28mformat\u001b[39m)\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1101\u001b[0m     result \u001b[38;5;241m=\u001b[39m convert_listlike(np\u001b[38;5;241m.\u001b[39marray([arg]), \u001b[38;5;28mformat\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/IdealDataInterface/lib/python3.11/site-packages/pandas/core/tools/datetimes.py:433\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[0;34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;66;03m# `format` could be inferred, or user didn't ask for mixed-format parsing.\u001b[39;00m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixed\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _array_strptime_with_fallback(arg, name, utc, \u001b[38;5;28mformat\u001b[39m, exact, errors)\n\u001b[1;32m    435\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m objects_to_datetime64(\n\u001b[1;32m    436\u001b[0m     arg,\n\u001b[1;32m    437\u001b[0m     dayfirst\u001b[38;5;241m=\u001b[39mdayfirst,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    441\u001b[0m     allow_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    442\u001b[0m )\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;66;03m# is in UTC\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/IdealDataInterface/lib/python3.11/site-packages/pandas/core/tools/datetimes.py:467\u001b[0m, in \u001b[0;36m_array_strptime_with_fallback\u001b[0;34m(arg, name, utc, fmt, exact, errors)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_array_strptime_with_fallback\u001b[39m(\n\u001b[1;32m    457\u001b[0m     arg,\n\u001b[1;32m    458\u001b[0m     name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    462\u001b[0m     errors: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m    463\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Index:\n\u001b[1;32m    464\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;124;03m    Call array_strptime, with fallback behavior depending on 'errors'.\u001b[39;00m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 467\u001b[0m     result, tz_out \u001b[38;5;241m=\u001b[39m array_strptime(arg, fmt, exact\u001b[38;5;241m=\u001b[39mexact, errors\u001b[38;5;241m=\u001b[39merrors, utc\u001b[38;5;241m=\u001b[39mutc)\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tz_out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    469\u001b[0m         unit \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdatetime_data(result\u001b[38;5;241m.\u001b[39mdtype)[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#df_combined(106)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_combined(107)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_106 = df_combined(300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_106.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_106.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets have  a look at the DF to see if it accords to expectations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_106.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_106.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_106.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_home_ids = ['100', '101', '102', '105', '106', '107', '109', '110', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '128', '129', '133', '134', '135', '136', '137', '138', '139', '140', '141', '143', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '173', '174', '175', '176', '177', '178', '179', '180', '181', '182', '183', '184', '185', '186', '187', '188', '189', '190', '191', '192', '193', '194', '195', '197', '199', '200', '201', '202', '203', '205', '206', '207', '208', '209', '210', '211', '212', '213', '214', '215', '216', '218', '219', '221', '222', '223', '224', '225', '226', '227', '228', '229', '230', '231', '232', '233', '234', '235', '236', '237', '238', '239', '240', '241', '242', '243', '244', '245', '246', '247', '248', '249', '250', '251', '252', '253', '254', '255', '256', '257', '258', '259', '260', '261', '262', '263', '264', '265', '266', '267', '268', '269', '270', '271', '272', '273', '274', '275', '276', '277', '278', '279', '280', '281', '282', '283', '284', '285', '286', '287', '288', '289', '290', '291', '292', '293', '294', '295', '296', '298', '299', '300', '301', '302', '303', '304', '305', '306', '307', '308', '309', '310', '311', '313', '315', '316', '317', '318', '319', '320', '321', '322', '323', '325', '326', '327', '328', '329', '330', '331', '332', '333', '334', '335', '47', '59', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '88', '89', '90', '91', '92', '93', '94', '96', '97', '98', '99']\n",
    "list_home_ids =[int(i) for i in list_home_ids]\n",
    "list_home_ids = sorted(list_home_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list_home_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "still_to_do =[224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 313, 315, 316, 317, 318, 319, 320, 321, 322, 323, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(list_home_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count = 0\n",
    "# for val in still_to_do:\n",
    "#     print(val)\n",
    "#     df_combined(val)\n",
    "#     count += 1\n",
    "#     print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_47 = df_combined(47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_47.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Need to check the metrics are consistent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets get the information from the home.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def home_info(homeid):\n",
    "\n",
    "    #print('home_info')\n",
    "\n",
    "    home_info = mdi.metadata.homes['home']\n",
    "    home_info = home_info[home_info.homeid == homeid]\n",
    "    home_info =home_info.reset_index()\n",
    "    #display(home_info)\n",
    "\n",
    "    appliance_list = ['fridgefreezer', 'grill', 'toaster', 'kettle', 'electricoven',\n",
    "       'washingmachine', 'freezer', 'fridge', 'microwave', 'dishwasher',\n",
    "       'vacuumcleaner', 'electrichob', 'washingmachinetumbledrier',\n",
    "       'electricshower', 'electricheater', 'tumbledrier', 'dehumidifier',\n",
    "       'other']\n",
    "\n",
    "    df_appliance = pd.DataFrame([0]*len(appliance_list), index=appliance_list).T\n",
    "    appliance_info = mdi.metadata.appliances['appliance']\n",
    "    appliance_info = appliance_info[appliance_info.homeid == homeid]\n",
    "    for val in df_appliance.columns:\n",
    "        if val in list(appliance_info.appliancetype):\n",
    "            df_appliance[val]= 1\n",
    "        else:\n",
    "            df_appliance[val] = 0\n",
    "    #display(df_appliance)\n",
    "\n",
    "\n",
    "    #print('weather center')\n",
    "    location_info = mdi.metadata.locations['location']\n",
    "    location = home_info.location.iloc[0]\n",
    "    location_info = location_info[location_info.locationid == location]\n",
    "    #display(location_info)\n",
    "\n",
    "\n",
    "    #print('people info')\n",
    "    people_info = mdi.metadata.people['person']\n",
    "    people_info = people_info[people_info.homeid == homeid].reset_index()\n",
    "    #display(people_info)\n",
    "\n",
    "    #print('tariff info')\n",
    "    df_tariff = pd.read_csv('/Users/barry/CodeAcademy/Ideal_dataset/metadata_and_surveys/metadata/tariff.csv')\n",
    "    #display(df_tariff[(df_tariff.homeid == homeid) & (df_tariff.energytype == 'electricity')])\n",
    "\n",
    "    #print('meter reading')\n",
    "    df_meter = pd.read_csv('/Users/barry/CodeAcademy/Ideal_dataset/metadata_and_surveys/metadata/meterreading.csv')\n",
    "    #display(df_meter[(df_meter.homeid == 106) & (df_meter.energytype == 'electricity')])    \n",
    "\n",
    "    room_info = mdi.metadata.rooms['room']\n",
    "    room_info = room_info[room_info.homeid == homeid]\n",
    "    #display(room_info[room_info.homeid == homeid])\n",
    "\n",
    "    room_info_condensed = pd.DataFrame({'number_of_rooms': [len(room_info)]})\n",
    "    room_info_condensed['sqm'] = room_info.floorarea.sum()\n",
    "    #display(room_info_condensed)\n",
    "    df_all = pd.merge(home_info, df_appliance, left_index=True, right_index=True) \n",
    "    df_all = pd.merge(df_all, location_info, left_index=True, right_index=True)\n",
    "    df_all = pd.merge(df_all, people_info, left_index=True, right_index=True)\n",
    "\n",
    "\n",
    "    display(df_all)\n",
    "    display(df_all.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "home_info(106)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meter = pd.read_csv('/Users/barry/CodeAcademy/Ideal_dataset/metadata_and_surveys/metadata/meterreading.csv')\n",
    "display(df_meter[(df_meter.homeid == 106) & (df_meter.energytype == 'electricity')])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "appliance_info = mdi.metadata.appliances['appliance'][mdi.metadata.appliances['appliance'].powertype == 'electric'].appliancetype.unique()\n",
    "display(appliance_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdi.metadata.locations.location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_106 = df_dwelling(106)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_106.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = pd.to_datetime('2017-06-01')\n",
    "end_date = pd.to_datetime('2018-06-01')\n",
    "df_106_year = df_106.loc[start_date:end_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_106_year.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_106_year.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.dates as mdates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_106.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hourly_consumption(df, homeid =None):\n",
    "    fig, ax = plt.subplots(figsize = (35, 5))\n",
    "    sns.lineplot(data = df, x = df.index, y = 'electric-combined', ax = ax)\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d %H:%M'))\n",
    "    ax.legend(['mains'])\n",
    "    fig.suptitle(f'Hourly electricity consumption for home {homeid}')\n",
    "        # Calculate the average hourly consumption\n",
    "    average_consumption = df['electric-combined'].mean()\n",
    "\n",
    "    # Draw a horizontal line at the average consumption\n",
    "    ax.axhline(y=average_consumption, color='r', linestyle='--')\n",
    "\n",
    "\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    average_consumption = df['electric-combined'].mean()\n",
    "    display(f'average daily consumption: {average_consumption}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hourly_consumption2(df, homeid=None):\n",
    "    # Calculate the average hourly consumption\n",
    "    average_consumption = df['electric-combined'].mean()\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Add line plot\n",
    "    fig.add_trace(go.Scatter(x=df.index, y=df['electric-combined'], mode='lines', name='mains'))\n",
    "\n",
    "    # Add horizontal line at the average consumption\n",
    "    fig.add_shape(type=\"line\",\n",
    "                  x0=df.index.min(), y0=average_consumption,\n",
    "                  x1=df.index.max(), y1=average_consumption,\n",
    "                  line=dict(color=\"Red\", width=2, dash=\"dash\"))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=f'Hourly electricity consumption for home {homeid}',\n",
    "        xaxis_title=\"Date\",\n",
    "        yaxis_title=\"Electric Combined\",\n",
    "        autosize=False,\n",
    "        width=1000,\n",
    "        height=500,\n",
    "        xaxis=dict(\n",
    "            tickformat=\"%Y-%m-%d %H:%M\"  # Display x-axis labels in the format \"Year-Month-Day Hour:Minute\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "    print(f'average daily consumption: {average_consumption}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_consumption2(df_106, 106)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_consumption(df_106)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap(df, homeid=None):\n",
    "    data = df[['electric-combined']]\n",
    "    pivot_data = data.pivot_table(index = data.index.date, columns = data.index.hour, values = 'electric-combined')\n",
    "    plt.figure(figsize=(10,8))\n",
    "    sns.heatmap(pivot_data, cmap = 'Oranges')\n",
    "    plt.suptitle(f'Hourly electricity consumption for home {homeid}')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def heatmap2(df, homeid=None):\n",
    "    data = df[['electric-combined']]\n",
    "    pivot_data = data.pivot_table(index = data.index.date, columns = data.index.hour, values = 'electric-combined')\n",
    "\n",
    "    fig = go.Figure(data=go.Heatmap(\n",
    "                   z=pivot_data.values,\n",
    "                   x=pivot_data.columns,\n",
    "                   y=pivot_data.index,\n",
    "                   colorscale='Oranges',\n",
    "                   hovertemplate='Day: %{y}<br>Time: %{x}<br>Value: %{z}<extra></extra>'\n",
    "                   ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=f'Hourly electricity consumption for home {homeid}',\n",
    "        xaxis_nticks=36,\n",
    "        width=800,\n",
    "        height = 800,\n",
    "        xaxis_title=\"Hour of the day\",\n",
    "        yaxis_title = 'Date')\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap2(df_106)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets get a graph showing the number of hours producing\n",
    "display(df_106.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_106['electric-combined'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_builder(df):\n",
    "    count_under_10000 = df[(df['electric-combined'] < 10000)].gas.count()\n",
    "    count_between_10000_20000 = df[(df['electric-combined'] >= 10000) & (df['electric-combined'] < 20000)].gas.count()\n",
    "    count_between_20000_30000 = df[(df['electric-combined'] >= 20000) & (df['electric-combined'] < 30000)].gas.count()\n",
    "    count_between_30000_40000 = df[(df['electric-combined'] >= 30000) & (df['electric-combined'] < 40000)].gas.count()\n",
    "    count_between_40000_50000 = df[(df['electric-combined'] >= 40000) & (df['electric-combined'] < 50000)].gas.count()\n",
    "    count_between_50000_60000 = df[(df['electric-combined'] >= 50000) & (df['electric-combined'] < 60000)].gas.count()\n",
    "    count_between_60000_70000 = df[(df['electric-combined'] >= 60000) & (df['electric-combined'] < 70000)].gas.count()\n",
    "    count_between_70000_80000 = df[(df['electric-combined'] >= 70000) & (df['electric-combined'] < 80000)].gas.count()\n",
    "\n",
    " \n",
    "    count_over_80000 = df[(df['electric-combined'] >= 80000)].gas.count()\n",
    "    bins = [count_under_10000, count_between_10000_20000, count_between_20000_30000, count_between_30000_40000, count_between_40000_50000,count_between_50000_60000,count_between_60000_70000,count_between_70000_80000, count_over_80000]\n",
    "    return bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def bin_builder(df):\n",
    "#     count_under_50 = df[(df['electric-combined'] < 50)].gas.count()\n",
    "#     count_between_50_100 = df[(df['electric-combined'] >= 50) & (df['electric-combined'] < 100)].gas.count()\n",
    "#     count_between_100_150 = df[(df['electric-combined'] >= 100) & (df['electric-combined'] < 150)].gas.count()\n",
    "#     count_between_150_200 = df[(df['electric-combined'] >= 150) & (df['electric-combined'] < 200)].gas.count()\n",
    "#     count_between_200_300 = df[(df['electric-combined'] >= 200) & (df['electric-combined'] < 300)].gas.count()\n",
    "#     count_between_300_400 = df[(df['electric-combined'] >= 300) & (df['electric-combined'] < 400)].gas.count()\n",
    "#     count_between_400_500 = df[(df['electric-combined'] >= 400) & (df['electric-combined'] < 500)].gas.count()\n",
    "#     count_between_500_750 = df[(df['electric-combined'] >= 500) & (df['electric-combined'] < 750)].gas.count()\n",
    "#     count_between_750_1000 = df[(df['electric-combined'] >= 750) & (df['electric-combined'] < 1000)].gas.count()\n",
    "#     count_between_1000_1500 = df[(df['electric-combined'] >= 1000) & (df['electric-combined'] < 1500)].gas.count()\n",
    "#     count_between_1500_2000 = df[(df['electric-combined'] >= 1500) & (df['electric-combined'] < 2000)].gas.count()\n",
    "#     count_over_2000 = df[(df['electric-combined'] >= 2000)].gas.count()\n",
    "#     bins = [count_under_50, count_between_50_100, count_between_100_150, count_between_150_200, count_between_200_300, count_between_300_400, count_between_400_500, count_between_500_750, count_between_750_1000, count_between_1000_1500, count_between_1500_2000, count_over_2000]\n",
    "#     return bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_hour_count(df, homeid=None):\n",
    "\n",
    "    bins = bin_builder(df)\n",
    "\n",
    "\n",
    "    counts = {\n",
    "        'count_under_10000': bins[0],\n",
    "        'count_between_10000_20000': bins[1],\n",
    "        'count_between_20000_30000': bins[2],\n",
    "        'count_between_30000_40000': bins[3],\n",
    "        'count_between_40000_50000': bins[4],\n",
    "        'count_between_50000_60000': bins[5],\n",
    "        'count_between_60000_70000': bins[6],\n",
    "        'count_between_70000_80000':bins[7],\n",
    "        'count_over_80000': bins[7]\n",
    "    }\n",
    "\n",
    "    # Convert the dictionary to a pandas DataFrame\n",
    "    df_counts = pd.DataFrame(list(counts.items()), columns=['Range', 'Count'])\n",
    "\n",
    "    # Create the barplot\n",
    "    sns.barplot(x='Count', y='Range', data=df_counts)\n",
    "    plt.title('Number of hours where electricity consumption falls within a given range')\n",
    "\n",
    "    for i in range(df_counts.shape[0]):\n",
    "        plt.text(df_counts.Count[i], i, df_counts.Count[i], va='center')\n",
    "\n",
    "       # Calculate the average\n",
    "    avg = df_counts['Count'].mean()\n",
    "\n",
    "    # Draw a vertical line at the average point\n",
    "    plt.axvline(x=avg, color='r', linestyle='--')\n",
    "\n",
    "\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_hour_count(df_106)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_hour_count(df_106)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isolate_peak(df):\n",
    "    df_peak = df[df['electric-combined'] > 70000]\n",
    "    return df_peak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_106_peak = isolate_peak(df_106)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def day_consumption(df):\n",
    "    df = df['electric-combined'].copy()\n",
    "    sns.boxplot(data = df, x = df.index.day_name(), y = 'electric-combined')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def day_consumption_outliersremoved(df):\n",
    "    df = df['electric-combined'].copy().reset_index()\n",
    "    Q1 = df.quantile(0.25)\n",
    "    Q3 = df.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    df = df[(df > (Q1 - 1.5 * IQR)) & (df < (Q3 + 1.5 * IQR))]\n",
    "    sns.boxplot(data = df, x = df.time.dt.day_name(), y = 'electric-combined')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hourly_consumption(df):\n",
    "    display(df.head())\n",
    "    df = df['electric-combined'].copy().reset_index()\n",
    "    display(df.head())\n",
    "    sns.boxplot(data = df, x = df.time.dt.hour, y = 'electric-combined')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hourly_consumption_outliersremoved(df):\n",
    "    df = df['electric-combined'].copy().reset_index()\n",
    "    Q1 = df.quantile(0.25)\n",
    "    Q3 = df.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    df = df[(df > (Q1 - 1.5 * IQR)) & (df < (Q3 + 1.5 * IQR))]\n",
    "    sns.boxplot(data = df, x = df.time.dt.hour, y = 'electric-combined')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_consumption_outliersremoved(df_106)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_consumption(df_106)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_consumption(df_106)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def peak_season_breakdown(df, ax=None, homeid =None):\n",
    "    df['season'] = df.index.to_series().dt.month%12 // 3 + 1\n",
    "\n",
    "    season_counts = df['season'].value_counts().sort_index()\n",
    "\n",
    "    # Calculate percentages\n",
    "    season_percentages = pd.DataFrame(season_counts / df.shape[0] * 100)\n",
    "    fig = season_percentages.T.plot(kind='bar', stacked=True, ax=ax)\n",
    "    fig.set_xticklabels(['Season'], rotation=0)\n",
    "    if ax is not None:\n",
    "        ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.05), ncol=4)\n",
    "\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_season_breakdown(df_106_peak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def peak_day_breakdown(df, ax=None, homeid=None):\n",
    "    df['day_of_week'] = df.index.to_series().dt.dayofweek\n",
    "    df['day_of_week'] = df.day_of_week.apply(lambda x: 'M' if x == 0 else 'T' if x == 1 else 'W' if x == 2 else 'Th' if x == 3 else 'F' if x == 4 else 'S' if x == 5 else 'Su' if x == 6 else x)\n",
    "\n",
    "    day_of_week_counts = df['day_of_week'].value_counts().sort_index()\n",
    "\n",
    "\n",
    "    # Calculate percentages\n",
    "    day_of_week_percentages = pd.DataFrame(day_of_week_counts / df.shape[0] * 100)\n",
    "    fig = day_of_week_percentages.T.plot(kind='bar',stacked=True, ax=ax)\n",
    "    fig.set_xticklabels(['Day of week'], rotation=0)\n",
    "    if ax is not None:\n",
    "        ax.legend(loc='lower center', bbox_to_anchor=(0.5, 1.05), ncol=4)\n",
    "    \n",
    "\n",
    "\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_day_breakdown(df_106_peak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def peak_time_of_day(df, ax=None, homeid =None):\n",
    "    def get_part_of_day(hour):\n",
    "        return (\n",
    "            \"morning\" if 5 <= hour <= 11\n",
    "            else\n",
    "            \"afternoon\" if 12 <= hour <= 17\n",
    "            else\n",
    "            \"evening\" if 18 <= hour <= 22\n",
    "            else\n",
    "            \"night\"\n",
    "        )\n",
    "\n",
    "    df['part_of_day'] = df.index.to_series().dt.hour.apply(get_part_of_day)\n",
    "\n",
    "    part_of_day_counts = df['part_of_day'].value_counts().sort_index()\n",
    "\n",
    "    # Calculate percentages\n",
    "    part_of_day_percentages = pd.DataFrame(part_of_day_counts / df.shape[0] * 100)\n",
    "\n",
    "    fig = part_of_day_percentages.T.plot(kind='bar', stacked=True, ax=ax)\n",
    "    fig.set_xticklabels(['Time of day'], rotation=0)\n",
    "    if ax is not None:\n",
    "        ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.05), ncol=4)\n",
    "\n",
    "\n",
    "\n",
    "    return fig\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def peak_combined_breakdown(df, homeid=None):\n",
    "\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(8, 5))\n",
    "    peak_time_of_day(df, ax=axs[0])\n",
    "    peak_day_breakdown(df, ax=axs[1])\n",
    "    peak_season_breakdown(df, ax=axs[2])\n",
    "    fig.suptitle('Peak electricity consumption breakdown')\n",
    "    fig.text(0.5, 1,'hours with consumption over 1000', ha='center', va='top')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_combined_breakdown(df_106_peak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def house_breakdown(homeid):\n",
    "    df = df_combined(homeid)\n",
    "    homeid = str(homeid)\n",
    "\n",
    "    power_hour_count(df, homeid)\n",
    "    day_consumption(df)\n",
    "    day_consumption_outliersremoved(df)\n",
    "    hourly_consumption2(df, homeid)\n",
    "    hourly_consumption_outliersremoved(df)\n",
    "    heatmap2(df, homeid)\n",
    "    peak_combined_breakdown(df,homeid)\n",
    "    \n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_breakdown(295)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IdealDataInterface",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
